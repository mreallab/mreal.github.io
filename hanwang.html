<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="author" content="Senton">
	<meta name="contact" content="hyj.hfut.mail@gmail.com">
	<meta name="copyright" content="All rights reserved @2015-2020, Senton">
	<title>Hanwang</title>
	<link href="static/css/bootstrap.min.css" type="text/css" rel="stylesheet">
	<link href="static/css/font-awesome.css" type="text/css" rel="stylesheet">
	<link href="static/css/amazing-separator.css" type="text/css" rel="stylesheet">
	<link href="static/css/jquery.nanoscroller.css" type="text/css" rel="stylesheet">
	<link href="static/css/style.css" type="text/css" rel="stylesheet">
</head>

<body>
	<div id="bgwrapper">
		<div id="bg"></div>
		<div id="overlayer"></div>
	</div>
	<div class="min-bio">
		<img class="bio-img img-circle" src="static/imgs/hanwang_profile.jpg" alt="">
		<div class="bio-tags">
			<span class="bio-tag">Hanwang Zhang</span>
		</div>
		<div id='aboutme' style="margin:0;padding:0;height:0;"></div> <!-- aboutme anchor-->

		<a href="javascript:void(0)" class="overlayer"></a>
	</div>
	<div id="profile">
		<div class="bio">
			<img class="bio-img img-circle" src="static/imgs/hanwang_profile.jpg" alt="">
			<p class="bio-name">Hanwang Zhang</p>
			<p style="text-align:center;"><img src='static/imgs/hanwang_character.png'></p>
			<p class="bio-motto">
				Ideas occur to us when they please, not when it pleases us.
			</p>
			<p class="bio-motto-auth">
				<small><i>---- by Max Weber</i></small>
			</p>
			<b id="contact"></b>
			<div class="bio-contact">
				<span class="bio-tag">Assistant Professor</span>
				<p><a href="http://scse.ntu.edu.sg">School of Computer Science and Engineering (SCSE)</a><br>
					<a href="http://www.ntu.edu.sg">Nanyang Technological University</a><br>
					Block N4 #02b-67, Nanyang Avenue, Singapore 639798 </p>
				<!--<p>email: <img src="images/email.jpg" align="bottom"></p>-->
				Email: hanwangzhang AT ntu.edu.sg (best way to contact me)</p>
			</div>
			<!-- news -->
			<!-- <div class="bio-news">
				<div class="nano">
					<div class="nano-content">					
						<div class="history">
							<div class="history-date first">
								<ul>
									<h2 class="clearfix">
										<a href="#nogo">2016年</a>
										<div class="history-mark">
											<h4>Two papers accepted in SIGIR</h4>
										</div>
									</h2>
								</ul>
							</div>
							<div class="history-date">
								<ul>
									<h2 class="clearfix">
										<a href="#nogo">2009</a>
										<div class="history-mark">
											<h4>Joined LMS</h4>
											<p></p>
										</div>
									</h2>
									<li class="green">
										<h3>Jun<span>2009</span></h3>
										<dl>
											<dt></dt><span>Graduated from ZJU</span>
										</dl>
									</li>
								</ul>
							</div>
						</div>
					</div>
				</div>
			</div> -->
			<div id="clustrmaps-widget"></div>
			<script type="text/javascript" id="clustrmaps"
				src="//cdn.clustrmaps.com/map_v2.js?d=fT8APhOGZnjwJZRym60cXoPZ3HEHia5dUnC7wD27gAI&cl=ffffff&w=a"></script>
			<!-- news -->

			<!-- <div class="bio-fork">
				<nav>
					<ul>
						<li><a href="#" class="fa fa-twitter"><span>Twitter</span></a></li>
						<li><a href="#" class="fa fa-facebook"><span>Facebook</span></a></li>
						<li><a href="#" class="fa fa-dribbble"><span>Dribbble</span></a></li>
						<li><a href="#" class="fa fa-github"><span>Github</span></a></li>
						<li><a href="mailto:hanwangzhang@gmail.com" class="fa fa-envelope-o"><span>Email</span></a></li>
					</ul>
				</nav>
			</div> -->
			<hr style="border:none; border-top:1px solid #444" />
			<div class="bio-organization">
				<!-- <br>
				<img src="static/imgs/next.png" alt="">
				<i class="hide-xs">&nbsp;·&nbsp;</i>
				<img src="static/imgs/nus.png" alt="">  -->
				<div id="copyright" class="fixed">
					Copyright @2015-2016 <span class="hide-xs">·</span> Created by Senton.
				</div>
			</div>
		</div>
		<div class="profileoverlay">
			<a class="pclose" href="javascript:void(0)"><i class="fa fa-times-circle-o"></i></a>
		</div>
	</div>

	<div id="nav">
		<span class="nav-item"><a href="#aboutme">About</a></span>
		<span class="nav-item"><a href="#contact">Contact</a></span>
		<span class="nav-item"><a href="#research">Research</a></span>
		<span class="nav-item"><a href="#publications">Publication</a></span>
		<span class="nav-item"><a href="files/hanwangcv.pdf">&nbsp;&nbsp;CV&nbsp;&nbsp;</a></span>
	</div>

	<div id="doc">
		<div id="content">

			<h4>MReaL Lab</h4>
			<b id="mreallab"></b>
			<p>Welcome to <a href="https://mreallab.github.io/">Machine Reasoning and Learning (MReaL) Lab</a>. MReaL
				Lab mainly focuses on computer vision, visual reasoning, machine learning and artificial intelligence. To be
				more specific, Our research topics cover but not limited to image captioning, visual question answering, scene
				graph generation, visual dialog, visual grounding, panoptic segmentation, meta-learning and so on.</p>
			<br>

			<h4>About me</h4>
			<b id="research"></b> <!-- publication anchor-->
			<p>I joined SCSE, Nanyang Technological University (NTU) as Assistant Professor in Jan 2018. I was doing a
				post-doc job at DVMM, whose boss is <a target="_blank" href="http://www.ee.columbia.edu/~sfchang/">Prof. Shih-Fu
					Chang</a>. Before this job, I worked with <a target="_blank" href="http://www.comp.nus.edu.sg/~chuats/">Prof.
					Tat-Seng Chua</a>, who is also my Ph.D supervisor (2009 - 2014) and Assoc. Prof. <a target="_blank"
					href="http://www.lv-nus.org/">Shuicheng Yan</a> (2013 - 2014). And, before this, I was an undergraduate
				student of <a href="http://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a> (2005 - 2009). In
				particular, I was a member of <a href='http://ckc.zju.edu.cn/english/' target='_blank'>Chu Kochen Honors
					College</a>.</p>
			<p>I was honored to be the valedictorian of NUS Commencement 2014 (<a
					href="https://www.youtube.com/watch?v=y4h8hT6q1bs">Youtube Link</a>, <a
					href="files/Valediction Speech Hanwang.pdf">valediction script</a>, and <a
					href="files/ABIR_zhang_thesis.pdf">Best Ph.D Thesis</a>)</p><br>

			<h4>Research</h4>
			<b id="publications"></b> <!-- publication anchor-->
			<p><b>Multimedia Knowledge Graph</b><br>Towards connecting images, videos, and common sense via knowledge graph,
				which can be used for visual reasoning, scene understanding, and natural language description generation.</p>
			<p><b>Multimedia Modeling for Large-scale Social Networks</b><br>Developing efficient algorithms for analyzing
				heterogeneous data on social networks such as users, images, videos, and their social relations.</p>
			<p><b>Representation Learning for Multimedia</b><br>Deep learning algorithms for learning image/video feature
				representations, which can be real-valued vectors for subsequent statistical modeling or binary codes for fast
				similarity search.</p>

			<br>
			<div>
				<div class="clearfix">
					<h4 style="float:left; display: inline-block;padding-right:1em;">Selected Publications</h4>
					<!-- ******* Your timeline ******** -->
					<div id="timeline">
						<ul class="t_lst">
							<li class="selected">All</li>
							<li>2019</li>
							<li>2018</li>
							<li>2017</li>
							<li>2016</li>
							<li>2015</li>
							<li>earlier</li>
						</ul>
					</div>
					<!-- ******* Your timeline ******** -->
				</div>
				<div id="pub_list">
					<ul class="2019" id="2019">
						<li class="paper">
							<p class="p title"><strong>Learning to Compose and Reason with Language Tree Structures for Visual
									Grounding</strong>
							</p>
							<p class="p author"><i>Richang Hong, Daqing Liu, Xiaoyu Mo, Xiangnan He, <b>Hanwang Zhang</b></i></p>
							<p class="p time">IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong>TPAMI</strong> 2019</p>
							<p class="p materials">[pdf coming soon]</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Context-Aware Visual Policy Network for Fined-Grained Image Captioning</strong>
							</p>
							<p class="p author"><i>Zheng-Jun Zha, Daqing Liu, <b>Hanwang Zhang</b>, Yongdong Zhang, Feng Wu</i></p>
							<p class="p time">IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong>TPAMI</strong> 2019</p>
							<p class="p materials">[pdf coming soon]</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Making History Matter: Gold-Critic Sequence Training for Visual Dialog</strong>
							</p>
							<p class="p author"><i>Tianhao Yang, Zheng-Jun Zha, <b>Hanwang Zhang</b></i></p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1902.09326v2">arxiv preprint</a>]&nbsp;&nbsp;[2nd
								place in <a href="https://visualdialog.org/challenge/2018">1st VisualDialog Challenge</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Scene Dynamics: Counterfactual Critic Multi-Agent Training for Scene Graph
									Generation</strong></p>
							<p class="p author"><i>Long Chen, <b>Hanwang Zhang</b>, Jun Xiao, Xiangnan He, Shiliang Pu, Shih-Fu
									Chang</i></p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1812.02347">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Explainability by Parsing: Neural Module Tree Networks for Natural Language
									Visual Grounding</strong></p>
							<p class="p author"><i>Daqing Liu, <b>Hanwang Zhang</b>, Zheng-Jun Zha, Feng Wu</i></p>
							<p class="p materials">[<a href="https://arxiv.org/pdf/1812.03299">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Explainable and Explicit Visual Reasoning over Scene Graphs</strong></p>
							<p class="p author"><i>Jiaxin Shi, <b>Hanwang Zhang</b>, Juanzi Li</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2019</strong>. Long Beach, USA. June 2019</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1812.01855">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Recursive Visual Attention in Visual Dialog</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i>Yulei Niu, <b>Hanwang Zhang</b>, Manli Zhang, Jianhong Zhang, Zhiwu Lu, Ji-Rong
									Wen</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2019</strong>. Long Beach, USA. June 2019</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1812.02664">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Auto-Encoding Scene Graphs for Image Captioning</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i>Xu Yang, Kaihua Tang, <b>Hanwang Zhang</b>, Jianfei Cai</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2019</strong>. Long Beach, USA. June 2019</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1812.02378">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Learning to Compose Dynamic Tree Structures for Visual
									Contexts</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Kaihua Tang, <b>Hanwang Zhang</b>, Baoyuan Wu, Wenhan Luo, Wei Liu</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2019</strong>. Long Beach, USA. June 2019</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1812.01880">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>DeepChannel: Salience Estimation by Contrastive Learning for Extractive
									Document Summarization</strong></p>
							<p class="p author"><i>Jiaxin Shi, Chen Liang, Lei Hou, Juanzi Li, Zhiyuan Liu, <b>Hanwang Zhang</b></i>
							</p>
							<p class="p time">The Thirty-Second AAAI Conference on Artificial Intelligence. <strong>AAAI</strong> 2019
							</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1811.02394">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/lliangchenc/DeepChannel">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Learning to Embed Sentences Using Attentive Recursive Trees</strong></p>
							<p class="p author"><i>Jiaxin Shi, Lei Hou, Juanzi Li, Zhiyuan Liu, <b>Hanwang Zhang</b></i></p>
							<p class="p time">The Thirty-Second AAAI Conference on Artificial Intelligence. <strong>AAAI</strong> 2019
							</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1811.02338">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/shijx12/AR-Tree">codes</a>]</p>
						</li>
					</ul>
					<ul class="2018" id="2018">
						<li class="paper">
							<p class="p title"><strong>Low-shot Learning via Covariance-Preserving Adversarial Augmentation
									Network</strong></p>
							<p class="p author"><i>Hang Gao, Zheng Shou, Alireza Zareian, <b>Hanwang Zhang</b>, Shih-Fu Chang</i></p>
							<p class="p time">Thirty-second Conference on Neural Information Processing Systems. <strong>NIPS</strong>
								2018 </p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1810.11730">arxiv preprint</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>More is Better: Precise and Detailed Image Captioning using Online Positive
									Recall and Missing Concepts Mining</strong></p>
							<p class="p author"><i>Mingxing Zhang, Yang Yang, <b>Hanwang Zhang</b>, Yanli Ji, Heng-Tao Shen, Tat-Seng
									Chua</i></p>
							<p class="p time">IEEE Transactions on Image Processing. <strong>TIP</strong> 2018 </p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Shuffle-Then-Assemble: Learning Object-Agnostic Visual Relationship
									Features</strong></p>
							<p class="p author"><i>Xu Yang, <b>Hanwang Zhang</b>, Jianfei Cai</i></p>
							<p class="p time">15th European Conference on Computer Vision. <strong>ECCV 2018</strong>. Munich,
								Germany. Sep 2018</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1808.00171">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/yangxuntu/vrd">merged in vtranse</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Context-Aware Visual Policy Network for Sequence-Level Image
									Captioning</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Daqing Liu, Zheng-Jun Zha, <b>Hanwang Zhang</b>, Yongdong Zhang, Feng Wu</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2018</strong>. Seoul, Korea,
								October 2018</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1808.05864">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/daqingliu/CAVP">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Discrete Factorization Machines for Fast Feature-based Recommendation</strong>
							</p>
							<p class="p author"><i>Han Liu, Xiangnan He, Fuli Feng, Liqiang Nie, Rui Liu, <b>Hanwang Zhang</b></i></p>
							<p class="p time">The 27th International Joint Conference on Artificial Intelligence. <strong>IJCAI
									2018</strong>. Stockholm, Sweden, July, 2018</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Multi-Level Policy and Reward Reinforcement Learning for Image
									Captioning</strong></p>
							<p class="p author"><i>An-An Liu, Ning Xu, <b>Hanwang Zhang</b>, Weizhi Nie, Yuting Su, Yongdong Zhang</i>
							</p>
							<p class="p time">The 27th International Joint Conference on Artificial Intelligence. <strong>IJCAI
									2018</strong>. Stockholm, Sweden, July, 2018</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Self-Supervised Video Hashing with Hierarchical Binary Auto-encoder</strong>
							</p>
							<p class="p author"><i>Jingkuan Song, <b>Hanwang Zhang</b>, Xiangpeng Li, Lianli Gao, Meng Wang, Richang
									Hong</i></p>
							<p class="p time">IEEE Transactions on Image Processing. <strong>TIP</strong> 2018 </p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Attributed Social Network Embedding</strong></p>
							<p class="p author"><i>Lizi Liao, Xiangnan He, <b>Hanwang Zhang</b>, Tat-Seng Chua</i></p>
							<p class="p time">IEEE Transactions on Knowledge and Data Engineering. <strong>TKDE</strong> 2018 </p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding
									Network</strong></p>
							<p class="p author"><i>Long Chen, <b>Hanwang Zhang</b>, Jun Xiao, Wei Liu, Shih-Fu Chang</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2018</strong>. Salt Late City, USA. June 2018</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1712.01928">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/zjuchenlong/sp-aen.cvpr18">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Grounding Referring Expressions in Images by Variational Context</strong></p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Yulei Niu, Shih-Fu Chang</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2018</strong>. Salt Late City, USA. June 2018</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1712.01892">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/yuleiniu/vc">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Learning to Guide Decoding for Image Captioning</strong></p>
							<p class="p author"><i>Wenhao Jiang, Lin Ma, Xinpeng Chen, <b>Hanwang Zhang</b>, Wei Liu</i></p>
							<p class="p time">The Thirty-Second AAAI Conference on Artificial Intelligence. <strong>AAAI
									2018</strong>. New Orleans, USA, Feb 2018</p>
						</li>
					</ul>
					<ul class="2017" id="2017">
						<li class="paper">
							<p class="p title"><strong>PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise
									R-FCN</strong></p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Zawlin Kyaw, Jinyang Yu, and Shih-Fu Chang</i></p>
							<p class="p time">International Conference on Computer Vision. <strong>ICCV 2017</strong>. Venice, Italy,
								October 2017</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1708.01956">arxiv preprint</a>]</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Improving Event Extraction via Cross-Modal Integration</strong></p>
							<p class="p author"><i>Tongtao Zhang, Spencer Whitehead, <b>Hanwang Zhang</b>, Hongzhi Li, Joseph Ellis,
									Lifu Huang, Wei Liu, Heng Ji and Shih-Fu Chang</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2017</strong>. Mountain View, CA
								USA, October 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Enhancing Micro-video Understanding by Harnessing External
									Sounds</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Liqiang Nie, Xiang Wang, Jianglong Zhang, Xiangnan He, <b>Hanwang Zhang</b>,
									Richang Hong and Qi Tian</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2017</strong>. Mountain View, CA
								USA, October 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Video Visual Relation Detection</strong></p>
							<p class="p author"><i>Xindi Shang, Tongwei Ren, Jingfan Guo, <b>Hanwang Zhang</b> and Tat-Seng Chua</i>
							</p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2017</strong>. Mountain View, CA
								USA, October 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Video Question Answering via Gradually Refined Attention over Appearance and
									Motion</strong></p>
							<p class="p author"><i>Dejing Xu, Zhou Zhao, Jun Xiao, Fei Wu, <b>Hanwang Zhang</b>, Xiangnan He and
									Yueting Zhuang</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2017</strong>. Mountain View, CA
								USA, October 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Attentional Factorization Machines: Learning the Weight of Feature Interactions
									via Attention Networks </strong></p>
							<p class="p author"><i>Jun Xiao, Hao Ye, Xiangnan He, <b>Hanwang Zhang</b>, Fei Wu and Tat-Seng Chua </i>
							</p>
							<p class="p time">The 26th International Joint Conference on Artificial Intelligence. <strong>IJCAI
									2017</strong>. Melbourne, Australia, August 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Videos Captioning with Attention-based LSTM and Semantic Consistency</strong>
							</p>
							<p class="p author"><i>Lianli Gao, Zhao Guo, <b>Hanwang Zhang</b>, Xing Xu, and Heng-Tao Shen</i></p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>VideoWhisper: Towards Discriminative Unsupervised Video Feature Learning with
									Attention Based Recurrent Neural Networks</strong></p>
							<p class="p author"><i>Na Zhao, <b>Hanwang Zhang</b>, Richang Hong, Meng Wang, Tat-Seng Chua</i></p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2017</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Attentive Collaborative Filtering: Multimedia Recommendation with Feature- and
									Item-level Attention</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Jingyuan Chen, <b>Hanwang Zhang</b>, Xiangnan He, Liqiang Nie, Wei Liu, Chua
									Tat-Seng</i></p>
							<p class="p time">International ACM SIGIR Conference on Research and Development in Information Retrieval.
								<strong>SIGIR 2017</strong>. Tokyo, Japan. August 2017</p>
							<p class="p materials">[<a href="tbd">pdf</a>]&nbsp;&nbsp;[<a href="tbd">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Visual Translation Embedding Network for Visual Relation Detection</strong></p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Zawlin Kyaw, Shih-Fu Chang, Tat-Seng Chua</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2017</strong>. Hawaii, USA. July 2017</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1702.08319">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/yangxuntu/vtranse">codes & data</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks for Image
									Captioning</strong></p>
							<p class="p author"><i>Long Chen, <b>Hanwang Zhang</b>, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu,
									Tat-Seng Chua</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2017</strong>. Hawaii, USA. July 2017</p>
							<p class="p materials">[<a href="https://arxiv.org/abs/1611.05594">arxiv preprint</a>]&nbsp;&nbsp;[<a
									href="https://github.com/zjuchenlong/sca-cnn">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Matryoshka Peek: Towards Learning Fine-grained, Robust, Discriminative Features
									for Product Search</strong></p>
							<p class="p author"><i>Zawlin Kyaw, Shuhan Qi, Ke Gao, <b>Hanwang Zhang</b>, Luming Zhang, Jun Xiao, Xuan
									Wang, Tat-Seng Chua</i></p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2017</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Neural Collaborative Filtering</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i>Xiangnan He, Lizi Liao, <b>Hanwang Zhang</b>, Liqiang Nie, Xia Hu, Tat-Seng
									Chua</i></p>
							<p class="p time">26th International World Wide Web Conference. <strong>WWW 2017</strong>. Perth,
								Australia, April 2017</p>
							<p class="p materials">[<a
									href="http://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="https://github.com/hexiangnan/theano-BPR">codes</a>]</p>
						</li>
					</ul>
					<ul class="2016" id="2016">
						<li class="paper">
							<p class="p title"><strong>I Know What You Want to Express: Sentence Element Inference by Incorporating
									External Knowledge Base</strong></p>
							<p class="p author"><i>Xiaochi Wei, Heyan Huang, Liqiang Nie, <b>Hanwang Zhang</b>, Xian-Ling Mao, Chua,
									Tat-Seng</i></p>
							<p class="p time">IEEE Transactions on Knowledge and Data Engineering. <strong>TKDE</strong> 2016</p>
						</li>

						<li class="paper">
							<p class="p title"><strong>Micro Tells Macro: Predicting the Popularity of Micro-Videos via a Transductive
									Model</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Jingyuan Chen, Xuemeng Song, Liqiang Nie, Xiang Wang, <b>Hanwang Zhang</b>,
									Tat-Seng Chua</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2016</strong>. Amsterdam, The
								Netherlands, October 2016</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Play and Rewind: Optimizing Binary Representations of Videos by Self-Supervised
									Temporal Hashing</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Meng Wang, Richang Hong, Tat-Seng Chua</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2016</strong>. Amsterdam, The
								Netherlands, October 2016</p>
							<p class="p materials">[<a href="files/SSTHmm2016.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="https://github.com/hanwangzhang/BLSTM">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Learning from Collective Intelligence: Feature Learning Using Social Images and
									Tags</strong></p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Xindi Shang, Huanbo Luan, Meng Wang, Tat-Seng
									Chua.</i></p>
							<p class="p time">ACM Transactions on Multimedia Computing, Communications and Applications.
								<strong>TOMM</strong> (formerly known as <strong>TOMCCAP</strong>) 2016</p>
							<p class="p materials">[<a href="files/tomm2016.pdf" />pdf</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Event Classification in Microblog via Social Tracking</strong></p>
							<p class="p author"><i>Yue Gao, <b>Hanwang Zhang</b>, Xibin Zhao, Shuicheng Yan</i></p>
							<p class="p time">ACM Transactions on Intelligent Systems and Technology. <strong>TIST</strong>. 2016</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Discrete Collaborative Filtering</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]&nbsp;&nbsp;<em style="color:red">Best Paper Honorable Mention</em></p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Fumin Shen, Wei Liu, Xiangnan He, Huanbo Luan, Chua
									Tat-Seng</i></p>
							<p class="p time">International ACM SIGIR Conference on Research and Development in Information Retrieval.
								<strong>SIGIR 2016</strong>. Pisa, Italy. July 2016</p>
							<p class="p materials">[<a href="files/DCFsigir2016.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="https://github.com/hanwangzhang/Discrete-Collaborative-Filtering">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Fast Matrix Factorization for Online Recommendation with Implicit
									Feedback</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i>Xiangnan He, <b>Hanwang Zhang</b>, Min-Yen Kan, Tat-Seng Chua </i></p>
							<p class="p time">International ACM SIGIR Conference on Research and Development in Information Retrieval.
								<strong>SIGIR 2016</strong>. Pisa, Italy. July 2016</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Online Collaborative Learning for Open-Vocabulary Visual Classifiers</strong>
							</p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Xindi Shang, Wenzhuo Yang, Huan Xu, Huanbo Luan, Tat-Seng
									Chua.</i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2016</strong>. Las Vegas, USA. Jun 2016</p>
							<p class="p materials">[<a href="files/OCLcvpr2016.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="https://github.com/hanwangzhang/Online-Collaborative-Learning">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Discrete Image Hashing Using Large Weakly Annotated Photo Collections</strong>
							</p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Na Zhao, Xindi Shang, Huanbo Luan, Tat-Seng Chua.</i></p>
							<p class="p time">The Thirtieth AAAI Conference on Artificial Intelligence. <strong>AAAI 2016</strong>.
								Phoenix, Arizona, USA. Feb 2016.</p>
						</li>
					</ul>
					<ul class="2015" id="2015">
						<li class="paper">
							<p class="p title"><strong>Learning Image and User Features for Recommendation in Social Networks</strong>
							</p>
							<p class="p author"><i>Xue Geng, <b>Hanwang Zhang</b>, Jingwen Bian, Tat-Seng Chua.</i></p>
							<p class="p time">IEEE International Conference on Computer Vision. <strong>ICCV 2015</strong>. Santiago,
								Chile. Nov 2015.</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Learning Features from Large-Scale, Noisy and Social Image-Tag
									Collection</strong></p>
							<p class="p author"><i><b>Hanwang Zhang</b>, Xindi Shang, Huanbo Luan, Yang Yang, Tat-Seng Chua. </i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2015</strong>. Brisbane,
								Australia. Oct 2015.</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Visual Coding in a Semantic Hierarchy</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i>Yang Yang, <b>Hanwang Zhang</b>, Mingxing Zhang, Fumin Shen, Xuelong Li. </i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2015</strong>. Brisbane,
								Australia. Oct 2015.</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Deep Fusion of Multiple Semantic Cues for Complex Event Recognition</strong>
							</p>
							<p class="p author">Xishan Zhang, <b>Hanwang Zhang</b>, Yongdong Zhang, Yang Yang, Meng Wang, Huanbo Luan,
								Jintao Li, Tat-Seng Chua.</i></p>
							<p class="p time">IEEE Transactions on Image Processing. <strong>TIP</strong> 2015</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Deep Aging Face Verification with Large Gaps</strong></p>
							<p class="p author">Luoqi Liu, Xiong Chao, <b>Hanwang Zhang</b>, Zhiheng Niu, Meng Wang, Shuicheng Yan</i>
							</p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2015</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Multimedia Summarization for Social Events in Microblog Stream</strong></p>
							<p class="p author"><i>Jingwen Bian, Yang Yang, <b>Hanwang Zhang</b>, Yue Gao, Tat-Seng Chua</i></p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2015</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Enhancing Video Event Recognition using Automatically Constructed
									Semantic-Visual Knowledge Base</strong></p>
							<p class="p author"><i>Xishan Zhang, Yang Yang, Yongdong Zhang, Huanbo Luan, Jintao Li, <b>Hanwang
										Zhang</b>, Tat-Seng Chua.</i></p>
							<p class="p time">IEEE Transactions on Multimedia. <strong>TMM</strong> 2015</p>
						</li>
					</ul>
					<ul class="0000" id="0000">
						<li class="paper">
							<p class="p title"><strong>Start from Scratch: Towards Automatically Identifying, Modeling, and Naming
									Visual Attributes</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Yang Yang, Huanbo Luan, Shuicheng Yan, Tat-Seng
									Chua. </i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2014</strong>. Orlando, USA. Nov
								2014. </p>
							<p class="p materials">[<a
									href="https://www.comp.nus.edu.sg/~hanwang/files/fp164-zhang.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="https://www.comp.nus.edu.sg/~hanwang/files/mm14_slides_zhang.pptx">slides</a>]&nbsp;&nbsp;[<a
									href="http://deeplearning.nextcenter.org/">demo (ID:deep, PWD: deep123456)</a>]&nbsp;&nbsp;[<a
									href="http://pub.nextcenter.org/deeplearning/modelParams.tar">models</a>]&nbsp;&nbsp;[<a
									href="https://www.comp.nus.edu.sg/~hanwang/codes/mm14.zip">codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Perception-Guided Multimodal Feature Fusion for Photo Aesthetics
									Assessment</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author">Luming Zhang, Yue Gao, Chao Zhang, <strong>Hanwang Zhang</strong>, Qi Tian, Roger
								Zimmermann.</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2014</strong>. Orlando, USA. Nov
								2014.</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>One of a Kind: User Profiling by Social Curation</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i>Xue Geng, <b>Hanwang Zhang</b>, Zheng Song, Yang Yang, Huanbo Luan, Tat-Seng
									Chua.</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2014</strong>. Orlando, USA. Nov
								2014.</p>
							<p class="p materials">[<a href="files/gx_31.pdf" />pdf</a>][<a href="files/MM-gengxue.pptx">slides</a>]
							</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Image Tagging with Social Assistance</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author">Yang Yang, Yue Gao, <strong>Hanwang Zhang</strong>, Jie Shao and Tat-Seng Chua.</i>
							</p>
							<p class="p time">ACM International Conference on Multimedia Retrieval. <strong>ICMR 2014</strong>.
								Glasgow, Scotland, Apr 2014.</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Robust (Semi-) Nonnegative Graph Embedding</strong></p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Zheng-Jun Zha, Yang Yang, Shuicheng Yan, Tat-Seng
									Chua.</i></p>
							<p class="p time">IEEE Transactions on Image Processing. <strong>TIP</strong> 2014</p>
							<p class="p materials">[<a href="files/hanwangTIP_double.pdf" />pdf</a>][<a
									href="codes/rnge.zip" />codes</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Attribute-augmented Semantic Hierarchy: Towards a Unified Framework for
									Content-based Image Retrieval</strong></p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Zheng-Jun Zha, Yang Yang, Shuicheng Yan, Yue Gao,
									Tat-Seng Chua.</i></p>
							<p class="p time">ACM Transactions on Multimedia Computing, Communications and Applications.
								<strong>TOMM</strong> (formerly known as <strong>TOMCCAP</strong>) 2014</p>
							<p class="p materials">[<a href="files/aash_extension.pdf" />pdf</a>]</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Attribute-augmented Semantic Hierarchy</strong>&nbsp;&nbsp;[<em
									style="color:blue">oral</em>]</p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Zheng-Jun Zha, Yang Yang, Shuicheng Yan, Yue Gao,
									Tat-Seng Chua.</i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2013</strong>. Barcelona, Spain.
								Oct 2014.</p>
							<p class="p materials">[<a href="files/mm012-zhang.pdf" />pdf</a>]&nbsp;&nbsp;[<a
									href="files/MM2013_slides.pptx">slides</a>]&nbsp;&nbsp;<em style="color:red">Best Student Paper</em>
							</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Attribute Feedback</strong>&nbsp;&nbsp;[<em style="color:blue">oral</em>]</p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Zheng-Jun Zha, Shuicheng Yan, Jingwen Bian,
									Tat-Seng Chua. </i></p>
							<p class="p time">ACM International Conference on Multimedia. <strong>MM 2012</strong>. Nara, Japan. Oct
								2012.</p>
							<p class="p materials">[<a href="files/zhangAF.pdf" />pdf</a>]&nbsp;&nbsp;[<a
									href="files/Attribute Feedback.pptx">slides</a>]&nbsp;&nbsp;[<a
									href="http://af.nextcenter.org/">demo</a>]&nbsp;&nbsp;<em style="color:red">Best Demo Runner-up</em>
							</p>
						</li>
						<li class="paper">
							<p class="p title"><strong>Robust Non-negative Graph Embedding: Towards Noisy Data, Unreliable Graphs, and
									Noisy Labels</strong></p>
							<p class="p author"><i><strong>Hanwang Zhang</strong>, Zheng-Jun Zha, Shuicheng Yan, Meng Wang, Tat-Seng
									Chua. </i></p>
							<p class="p time">IEEE International Conference on Computer Vision and Pattern Recognition. <strong>CVPR
									2012</strong>. Rhode Island, USA. June 2012.</p>
							<p class="p materials">[<a href="files/cvpr2012.pdf">pdf</a>]&nbsp;&nbsp;[<a
									href="codes/rnge.zip">codes</a>]</p>
						</li>
					</ul>
				</div>
			</div>
		</div>
	</div>
	<a href="#" id="backtop" style="text-decoration:none;"></a>
	<script src="static/scripts/jquery-1.9.1.min.js"></script>
	<script src="static/scripts/jquery.nanoscroller.js"></script>

	<script>
		var DELTA = 10;
		function systole() {
			if (!$(".history").length) {
				return;
			}
			var $warpEle = $(".history-date"),
				$targetA = $warpEle.find("h2 a,ul li dl dt a"),
				parentH,
				eleTop = [];

			parentH = $warpEle.parent().height();
			$warpEle.parent().css({ "height": 59 });

			setTimeout(function () {

				$warpEle.find("ul").children(":not('h2:first')").each(function (idx) {
					eleTop.push($(this).position().top);
					$(this).css({ "margin-top": -eleTop[idx] }).children().hide();
				}).animate({ "margin-top": 0 }, 1600).children().fadeIn();

				$warpEle.parent().animate({ "height": parentH }, 1200);

				$warpEle.find("ul").children(":not('h2:first')").addClass("bounceInDown").css({ "-webkit-animation-duration": "2s", "-webkit-animation-delay": "0", "-webkit-animation-timing-function": "ease", "-webkit-animation-fill-mode": "both" }).end().children("h2").css({ "position": "relative" });

			}, 600);

			$targetA.click(function () {
				$(this).parent().css({ "position": "relative" });
				$(this).parent().siblings().slideToggle();
				$warpEle.parent().removeAttr("style");
				return false;
			});
		};

		$(function () {
			$(".bio .bio-news .nano").css('height', '800px').nanoScroller();
			systole();

			// 返回顶部
			var bTop = $("#backtop"), jWin = $(window);
			//返回顶部按钮判断
			jWin.scroll(function () {
				var t = jWin.scrollTop(), h = jWin.height();
				if (t > h && bTop.is(":hidden")) {
					bTop.fadeIn();
				} else if (t < h && !bTop.is(":hidden")) {
					bTop.fadeOut();
				};
			});

			//
			var minbio = $(".min-bio"),
				minbioOverlayer = minbio.find('.overlayer'),
				profile = $("#profile"),
				profileOverlayer = profile.find('.profileoverlay'),
				profileClose = profileOverlayer.find('.pclose');
			minbioOverlayer.click(function (event) {
				minbio.hide('400', function () {
					profileOverlayer.show();
					profile.css('margin-left', '0');
					profileClose.click(function (event) {
						profileOverlayer.hide('1', function () {
							profile.css('margin-left', '');
							minbio.show('400', function () {

							});
						});
					});
				});
			});

			function restore2Normal() {
				minbio.css('display', '');
				profileOverlayer.css('display', '');
				profile.css('margin-left', '');
			}
			// customized help functions
			function adjustHorizontalLayout() {
				var $docwidth = $(document).width();
				$docwidth > 1024 && restore2Normal();
				if ($docwidth > 1024 && $docwidth <= 1499) {
					$("div#doc").css('width', '100%').css('width', '-=320px');
					$("div#nav").css({ 'width': $("div#doc").outerWidth() + 'px' });
				} else if ($docwidth >= 2400) {
					$("div#doc").css('width', '100%').css('width', '-=480px');
					$("div#nav").css({ 'width': $("div#doc").outerWidth() + 'px' });
				} else {
					$("div#doc").css('width', '');
					$("div#nav").css('width', '');
				}

			}
			function adjustVirticalLayout() {
				var $window = $(window),
					$background = $("div#bgwrapper"),
					$profile = $("div#profile"),
					$navigation = $("div#nav");

				var windowScrollTop = $window.scrollTop(),
					windowHeight = $window.outerHeight() - 0 * DELTA,
					windowWidth = $window.outerWidth(),
					backgroundHeight = $background.outerHeight(),
					profileHeight = $profile.outerHeight(),
					navHeight = $navigation.outerHeight();

				// profile
				if (windowWidth > 1024) {
					if (windowScrollTop + windowHeight + 200 >= backgroundHeight + profileHeight) {
						$profile.addClass("fixed");
					} else {
						$profile.removeClass("fixed");
					}
				} else {
					if (windowScrollTop + windowHeight >= profileHeight) {
						$profile.addClass("fixed");
					} else {
						$profile.removeClass("fixed");
					}
				}


				// navigation
				if (windowScrollTop + navHeight >= backgroundHeight) {
					$navigation.addClass("fixed");
				} else {
					$navigation.removeClass("fixed");
				};
			}

			adjustHorizontalLayout();
			adjustVirticalLayout();
			// bind resize to ajust layout
			$(window).resize(adjustHorizontalLayout);
			// bind scroll to adjust layout
			$(window).scroll(adjustVirticalLayout);


			////////////
			var util = util || {};
			; (function (o, $) {
				var _self = o;
				_self.MouseoverSwapTab = function (name, title, content, Sub, cur) {
					$(name + ' ' + title).mouseover(function () {
						$(this).addClass(cur).siblings().removeClass(cur);
						$(content + " > " + Sub).eq($(name + ' ' + title).index(this)).show().siblings().hide();
					});
				}
				_self.ClickSwapTab = function (name, title, content, Sub, cur) {
					$(name + ' ' + title).click(function () {
						$(this).addClass(cur).siblings().removeClass(cur);
						var idx = $(name + ' ' + title).index(this);
						if (idx == 0) {
							$(content + " > " + Sub).eq(idx).show().siblings().show();
						} else {
							$(content + " > " + Sub).eq(idx - 1).show().siblings().hide();
						}
					});
				}
			})(util, jQuery)
			util.ClickSwapTab("div#timeline ul.t_lst", "li", "div#pub_list", "ul", "selected");
		});
	</script>
</body>

</html>